# -*- coding: utf-8 -*-
"""CV Project - Low Light Image Enhancement

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qQIpoEOweQ09cg15k7V3AxRHqF80W0Ko
"""

# Cell 1: Imports
import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, UpSampling2D, Input, Conv2DTranspose
from tensorflow.keras.models import Model
from tensorflow.keras.datasets import mnist
from tensorflow.keras.callbacks import EarlyStopping
from skimage.util import random_noise
import tensorflow as tf

from google.colab import drive
drive.mount('/content/drive')

import os
import cv2
import albumentations as A
from albumentations.augmentations.transforms import GaussNoise, RandomBrightnessContrast
from tqdm import tqdm
from sklearn.model_selection import train_test_split

# Cell 2: Preprocess Low-Light Images
input_folder_low = '/content/drive/MyDrive/LOLdataset/our485/low' #low light images folder
output_folder_preprocessed_low = '/content/drive/MyDrive/LOLdataset/our485/low_preprocessed'

os.makedirs(output_folder_preprocessed_low, exist_ok=True)

for filename in os.listdir(input_folder_low):
    if filename.endswith('.png'):
        # Read the low-light image
        image_path_low = os.path.join(input_folder_low, filename)
        low_light_image = cv2.imread(image_path_low)

        #CLAHE
        b, g, r = cv2.split(low_light_image)
        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
        clahe_b = clahe.apply(b)
        clahe_g = clahe.apply(g)
        clahe_r = clahe.apply(r)
        clahe_color_image = cv2.merge([clahe_b, clahe_g, clahe_r])

        #Linear Brightening
        min_intensity = np.min(clahe_color_image)
        max_intensity = np.max(clahe_color_image)
        brightened_image = np.clip((clahe_color_image - min_intensity) * (255.0 / (max_intensity - min_intensity) * 2.0), 0, 255).astype(np.uint8)

        output_path_preprocessed_low = os.path.join(output_folder_preprocessed_low, filename)
        cv2.imwrite(output_path_preprocessed_low, brightened_image)

# Cell 3: Augment Low-Light Images

low_light_folder = '/content/drive/MyDrive/LOLdataset/our485/preprocessed_low'
high_quality_folder = '/content/drive/MyDrive/LOLdataset/our485/high'
augmented_low_folder = '/content/drive/MyDrive/LOLdataset/our485/augmented_low'
augmented_high_folder = '/content/drive/MyDrive/LOLdataset/our485/augmented_high'

#Albumentations transform for brightness, contrast, and noise adjustments
transform = A.Compose([
    A.GaussNoise(var_limit=(10.0, 50.0), p=0.5),
    A.RandomBrightnessContrast(brightness_limit=0, contrast_limit=(-0.2, 0.2), p=1.0),
])

num_augmentations = 2

os.makedirs(augmented_low_folder, exist_ok=True)
os.makedirs(augmented_high_folder, exist_ok=True)

## Function to augment low-light images and save corresponding high-quality image pairs.
def augment_and_save(low_light_path, high_quality_path, augmented_low_folder, augmented_high_folder, num_augmentations):
    low_light_image = cv2.imread(low_light_path)

    for i in range(num_augmentations):

        augmented = transform(image=low_light_image)
        augmented_low_light_image = augmented['image']
        augmented_low_light_image = np.clip(augmented_low_light_image, 0, 255)

        low_light_filename = os.path.basename(low_light_path)
        augmented_low_light_path = os.path.join(augmented_low_folder, f'aug_{low_light_filename}_{i+1}.png')
        print(f"Saved augmented low light image: {augmented_low_light_path}")

        # Read high-quality image for each augmentation
        high_quality_image = cv2.imread(high_quality_path)

        # Save corresponding high-quality images
        high_quality_filename = os.path.basename(high_quality_path)
        augmented_high_quality_path = os.path.join(augmented_high_folder, f'aug_{high_quality_filename}_{i+1}.png')
        cv2.imwrite(augmented_high_quality_path, high_quality_image)
        print(f"Saved augmented high quality image: {augmented_high_quality_path}")

# Applying of augmentation to each pair of low light and high-quality images
for low_light_filename in tqdm(os.listdir(low_light_folder)):
    low_light_path = os.path.join(low_light_folder, low_light_filename)
    high_quality_path = os.path.join(high_quality_folder, low_light_filename)

    print(f"Low light path: {low_light_path}")
    print(f"High quality path: {high_quality_path}")

    augment_and_save(low_light_path, high_quality_path, augmented_low_folder, augmented_high_folder, num_augmentations)

# Cell 4: Load and Preprocess Images for Training
np.random.seed(42)

# Function to load and apply preprocessing on images
def load_images(path):
    images = []
    for filename in os.listdir(path):
        img = cv2.imread(os.path.join(path, filename))
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        img = img / 255.0
        images.append(img)
    return np.array(images)

input_folder_preprocessed_low = '/content/drive/MyDrive/LOLdataset/our485/augmented_low'
input_folder_high = '/content/drive/MyDrive/LOLdataset/our485/augmented_high'

preprocessed_low_images = load_images(input_folder_preprocessed_low)
high_images = load_images(input_folder_high)

# Splitting the data into training and validation sets
X_train, X_val, y_train, y_val = train_test_split(preprocessed_low_images, high_images, test_size=0.2, random_state=42)

from tensorflow import keras
from tensorflow.keras import layers

# Cell 5: Define Denoising Model
model = keras.Sequential([

    layers.Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=(None, None, 3)),
    layers.Conv2D(64, (3, 3), activation='relu', padding='same'),
    layers.Conv2D(128, (3, 3), activation='relu', padding='same'),
    layers.Conv2D(3, (3, 3), activation='linear', padding='same')
])

optimizer = keras.optimizers.Adam(learning_rate=0.001)
model.compile(optimizer=optimizer, loss='mse')

model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=10, batch_size=32)

# Cell 6: Save the Trained Model
model.save('denoising_model.h5')
#Saving the model for future use

# Cell 7: Evaluate Denoising Model on New Images
import os
import cv2
import numpy as np
from tensorflow import keras

def load_and_preprocess_images(path, clahe_clip_limit=3.0, clahe_tile_grid=(8, 8), brightness_factor=2.5):
    images = []

    for filename in os.listdir(path):
        img = cv2.imread(os.path.join(path, filename))
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

        lab = cv2.cvtColor(img, cv2.COLOR_RGB2LAB)
        l, a, b = cv2.split(lab)

        clahe = cv2.createCLAHE(clipLimit=clahe_clip_limit, tileGridSize=clahe_tile_grid)
        l_clahe = clahe.apply(l)
        lab_clahe = cv2.merge([l_clahe, a, b])

        clahe_color_image = cv2.cvtColor(lab_clahe, cv2.COLOR_LAB2RGB)

        brightness_adjusted_image = np.clip(img * brightness_factor, 0, 255).astype(np.uint8)
        preprocessed_image = brightness_adjusted_image / 255.0

        images.append(preprocessed_image)

    return np.array(images)

input_folder_eval_low = '/content/drive/MyDrive/LOLdataset/eval15/low'
output_folder_eval_denoised = '/content/drive/MyDrive/LOLdataset/eval15/denoised'

os.makedirs(output_folder_eval_denoised, exist_ok=True)

eval_low_images = load_and_preprocess_images(input_folder_eval_low)

# Loading the pre-trained denoising model
loaded_model = keras.models.load_model('denoising_model.h5')

for i in range(len(eval_low_images)):
    input_image = np.expand_dims(eval_low_images[i], axis=0)
    denoised_image = loaded_model.predict(input_image)
    denoised_image = np.clip(denoised_image, 0, 1) * 255.0
    denoised_image = denoised_image.astype(np.uint8)[0]

    #Final Result
    output_path_denoised = os.path.join(output_folder_eval_denoised, f'denoised_{i}.png')
    cv2.imwrite(output_path_denoised, cv2.cvtColor(denoised_image, cv2.COLOR_RGB2BGR))

import cv2
import numpy as np
from tensorflow import keras

def preprocess_image(img, clahe_clip_limit=3.0, clahe_tile_grid=(8, 8), brightness_factor=2.5):
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

    lab = cv2.cvtColor(img, cv2.COLOR_RGB2LAB)
    l, a, b = cv2.split(lab)

    clahe = cv2.createCLAHE(clipLimit=clahe_clip_limit, tileGridSize=clahe_tile_grid)
    l_clahe = clahe.apply(l)
    lab_clahe = cv2.merge([l_clahe, a, b])

    clahe_color_image = cv2.cvtColor(lab_clahe, cv2.COLOR_LAB2RGB)

    brightness_adjusted_image = np.clip(img * brightness_factor, 0, 255).astype(np.uint8)
    preprocessed_image = brightness_adjusted_image / 255.0

    return preprocessed_image

# Load the pre-trained denoising model
loaded_model = keras.models.load_model('denoising_model.h5')

# Load and preprocess the input image
input_image_path = '/content/wildlife.jpeg'
input_image = cv2.imread(input_image_path)
preprocessed_image = preprocess_image(input_image)

# Apply the denoising model to the input image
input_image_batch = np.expand_dims(preprocessed_image, axis=0)
denoised_image = loaded_model.predict(input_image_batch)
denoised_image = np.clip(denoised_image, 0, 1) * 255.0
denoised_image = denoised_image.astype(np.uint8)[0]

# Save the denoised image
output_path_denoised = '/content/denoised_wildlife.png'
cv2.imwrite(output_path_denoised, cv2.cvtColor(denoised_image, cv2.COLOR_RGB2BGR))

